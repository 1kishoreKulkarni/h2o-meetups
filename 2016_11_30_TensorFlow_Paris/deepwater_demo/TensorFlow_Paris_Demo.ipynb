{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tensorflow with H2O \n",
    "\n",
    "This notebook shows how to use the tensorflow backend to tackle a simple image classification problem.\n",
    "\n",
    "We start by connecting to our h2o cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>54 mins 37 secs</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.11.0.99999</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>6 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>ubuntu</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>8.86 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>2.7.12 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------\n",
       "H2O cluster uptime:         54 mins 37 secs\n",
       "H2O cluster version:        3.11.0.99999\n",
       "H2O cluster version age:    6 days\n",
       "H2O cluster name:           ubuntu\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    8.86 Gb\n",
       "H2O cluster total cores:    8\n",
       "H2O cluster allowed cores:  8\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "Python version:             2.7.12 final\n",
       "--------------------------  ----------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "h2o.init(port=54321, nthreads=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we make sure that the H2O cluster has the DeepWater distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from h2o.estimators.deepwater import H2ODeepWaterEstimator\n",
    "if not H2ODeepWaterEstimator.available(): exit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load some python utilities library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and finally we configure the IPython notebook to have nice visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import Image, display, HTML\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set the path to your h2o installation\n",
    "and download the 'bigdata' dataset using `./gradlew syncBigdataLaptop` from the H2O source distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H2O_PATH=os.path.expanduser(\"~/h2o-3/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification Task\n",
    "\n",
    "H2O DeepWater allows you to specify a list of URIs (file paths) or URLs (links) to images, together with a response column (either a class membership (enum) or regression target (numeric)).\n",
    "\n",
    "For this example, we use a small dataset that has a few hundred images, and three classes: cat, dog and mouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "[267, 2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>C1                                                             </th><th>C2  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>bigdata/laptop/deepwater/imagenet/cat/102194502_49f003abd9.jpg </td><td>cat </td></tr>\n",
       "<tr><td>bigdata/laptop/deepwater/imagenet/cat/11146807_00a5f35255.jpg  </td><td>cat </td></tr>\n",
       "<tr><td>bigdata/laptop/deepwater/imagenet/cat/1140846215_70e326f868.jpg</td><td>cat </td></tr>\n",
       "<tr><td>bigdata/laptop/deepwater/imagenet/cat/114170569_6cbdf4bbdb.jpg </td><td>cat </td></tr>\n",
       "<tr><td>bigdata/laptop/deepwater/imagenet/cat/1217664848_de4c7fc296.jpg</td><td>cat </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "frame = h2o.import_file(H2O_PATH + \"/bigdata/laptop/deepwater/imagenet/cat_dog_mouse.csv\")\n",
    "print(frame.dim)\n",
    "print(frame.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build a LeNet image classification model in H2O, simply specify `network = \"lenet\"` and the **Tensorflow** backend to use the tensorflow lenet implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepwater Model Build progress: |█████████████████████████████████████████| 100%\n",
      "Model Details\n",
      "=============\n",
      "H2ODeepWaterEstimator :  Deep Water\n",
      "Model Key:  deepwater_tf_simple\n",
      "\n",
      "\n",
      "ModelMetricsMultinomial: deepwater\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.347845369945\n",
      "RMSE: 0.589784172342\n",
      "LogLoss: 0.981696653168\n",
      "Mean Per-Class Error: 0.482660793786\n",
      "Confusion Matrix: vertical: actual; across: predicted\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>cat</b></td>\n",
       "<td><b>dog</b></td>\n",
       "<td><b>mouse</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>74.0</td>\n",
       "<td>7.0</td>\n",
       "<td>9.0</td>\n",
       "<td>0.1777778</td>\n",
       "<td>16 / 90</td></tr>\n",
       "<tr><td>42.0</td>\n",
       "<td>26.0</td>\n",
       "<td>17.0</td>\n",
       "<td>0.6941176</td>\n",
       "<td>59 / 85</td></tr>\n",
       "<tr><td>49.0</td>\n",
       "<td>4.0</td>\n",
       "<td>39.0</td>\n",
       "<td>0.5760870</td>\n",
       "<td>53 / 92</td></tr>\n",
       "<tr><td>165.0</td>\n",
       "<td>37.0</td>\n",
       "<td>65.0</td>\n",
       "<td>0.4794007</td>\n",
       "<td>128 / 267</td></tr></table></div>"
      ],
      "text/plain": [
       "cat    dog    mouse    Error     Rate\n",
       "-----  -----  -------  --------  ---------\n",
       "74     7      9        0.177778  16 / 90\n",
       "42     26     17       0.694118  59 / 85\n",
       "49     4      39       0.576087  53 / 92\n",
       "165    37     65       0.479401  128 / 267"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-3 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.5205992</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.82397</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.520599\n",
       "2    0.82397\n",
       "3    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>training_speed</b></td>\n",
       "<td><b>epochs</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>samples</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-11-30 09:36:48</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-11-30 09:36:50</td>\n",
       "<td> 1.989 sec</td>\n",
       "<td>564 obs/sec</td>\n",
       "<td>3.8352060</td>\n",
       "<td>1</td>\n",
       "<td>1024.0</td>\n",
       "<td>0.8077921</td>\n",
       "<td>3.3077188</td>\n",
       "<td>0.6629213</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-11-30 09:36:55</td>\n",
       "<td> 7.348 sec</td>\n",
       "<td>2149 obs/sec</td>\n",
       "<td>57.5280899</td>\n",
       "<td>15</td>\n",
       "<td>15360.0</td>\n",
       "<td>0.6257361</td>\n",
       "<td>0.9911735</td>\n",
       "<td>0.4831461</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-11-30 09:37:00</td>\n",
       "<td>12.678 sec</td>\n",
       "<td>2385 obs/sec</td>\n",
       "<td>111.2209738</td>\n",
       "<td>29</td>\n",
       "<td>29696.0</td>\n",
       "<td>0.5897842</td>\n",
       "<td>0.9816967</td>\n",
       "<td>0.4794007</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-11-30 09:37:06</td>\n",
       "<td>18.014 sec</td>\n",
       "<td>2479 obs/sec</td>\n",
       "<td>164.9138577</td>\n",
       "<td>43</td>\n",
       "<td>44032.0</td>\n",
       "<td>0.8095860</td>\n",
       "<td>10.8698045</td>\n",
       "<td>0.6554307</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-11-30 09:37:11</td>\n",
       "<td>23.315 sec</td>\n",
       "<td>2534 obs/sec</td>\n",
       "<td>218.6067416</td>\n",
       "<td>57</td>\n",
       "<td>58368.0</td>\n",
       "<td>0.8095859</td>\n",
       "<td>10.8075838</td>\n",
       "<td>0.6554307</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-11-30 09:37:16</td>\n",
       "<td>28.628 sec</td>\n",
       "<td>2567 obs/sec</td>\n",
       "<td>272.2996255</td>\n",
       "<td>71</td>\n",
       "<td>72704.0</td>\n",
       "<td>0.8095858</td>\n",
       "<td>10.7393858</td>\n",
       "<td>0.6554307</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-11-30 09:37:22</td>\n",
       "<td>33.936 sec</td>\n",
       "<td>2590 obs/sec</td>\n",
       "<td>325.9925094</td>\n",
       "<td>85</td>\n",
       "<td>87040.0</td>\n",
       "<td>0.8095855</td>\n",
       "<td>10.6550124</td>\n",
       "<td>0.6554307</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-11-30 09:37:27</td>\n",
       "<td>39.239 sec</td>\n",
       "<td>2608 obs/sec</td>\n",
       "<td>379.6853933</td>\n",
       "<td>99</td>\n",
       "<td>101376.0</td>\n",
       "<td>0.8095851</td>\n",
       "<td>10.5413824</td>\n",
       "<td>0.6554307</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-11-30 09:37:32</td>\n",
       "<td>44.541 sec</td>\n",
       "<td>2621 obs/sec</td>\n",
       "<td>433.3782772</td>\n",
       "<td>113</td>\n",
       "<td>115712.0</td>\n",
       "<td>0.8095841</td>\n",
       "<td>10.3639527</td>\n",
       "<td>0.6554307</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-11-30 09:37:38</td>\n",
       "<td>49.853 sec</td>\n",
       "<td>2630 obs/sec</td>\n",
       "<td>487.0711610</td>\n",
       "<td>127</td>\n",
       "<td>130048.0</td>\n",
       "<td>0.8095812</td>\n",
       "<td>10.0629951</td>\n",
       "<td>0.6554307</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-11-30 09:37:38</td>\n",
       "<td>49.973 sec</td>\n",
       "<td>2628 obs/sec</td>\n",
       "<td>487.0711610</td>\n",
       "<td>127</td>\n",
       "<td>130048.0</td>\n",
       "<td>0.5897842</td>\n",
       "<td>0.9816967</td>\n",
       "<td>0.4794007</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_classification_error\n",
       "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------------------------\n",
       "    2016-11-30 09:36:48  0.000 sec                     0         0             0          nan              nan                 nan\n",
       "    2016-11-30 09:36:50  1.989 sec   564 obs/sec       3.83521   1             1024       0.807792         3.30772             0.662921\n",
       "    2016-11-30 09:36:55  7.348 sec   2149 obs/sec      57.5281   15            15360      0.625736         0.991174            0.483146\n",
       "    2016-11-30 09:37:00  12.678 sec  2385 obs/sec      111.221   29            29696      0.589784         0.981697            0.479401\n",
       "    2016-11-30 09:37:06  18.014 sec  2479 obs/sec      164.914   43            44032      0.809586         10.8698             0.655431\n",
       "    2016-11-30 09:37:11  23.315 sec  2534 obs/sec      218.607   57            58368      0.809586         10.8076             0.655431\n",
       "    2016-11-30 09:37:16  28.628 sec  2567 obs/sec      272.3     71            72704      0.809586         10.7394             0.655431\n",
       "    2016-11-30 09:37:22  33.936 sec  2590 obs/sec      325.993   85            87040      0.809586         10.655              0.655431\n",
       "    2016-11-30 09:37:27  39.239 sec  2608 obs/sec      379.685   99            101376     0.809585         10.5414             0.655431\n",
       "    2016-11-30 09:37:32  44.541 sec  2621 obs/sec      433.378   113           115712     0.809584         10.364              0.655431\n",
       "    2016-11-30 09:37:38  49.853 sec  2630 obs/sec      487.071   127           130048     0.809581         10.063              0.655431\n",
       "    2016-11-30 09:37:38  49.973 sec  2628 obs/sec      487.071   127           130048     0.589784         0.981697            0.479401"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = H2ODeepWaterEstimator(epochs      = 500, \n",
    "                              network     = \"lenet\", \n",
    "                              image_shape = [28,28],  ## provide image size\n",
    "                              channels    = 3,\n",
    "                              backend     = \"tensorflow\",\n",
    "                              model_id    = \"deepwater_tf_simple\")\n",
    "\n",
    "model.train(x = [0], # file path e.g. xxx/xxx/xxx.jpg\n",
    "            y = 1, # label cat/dog/mouse\n",
    "            training_frame = frame)\n",
    "\n",
    "model.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like to build your own Tensorflow network architecture, then this is easy as well.\n",
    "In this example script, we are using the **Tensorflow** backend. \n",
    "Models can easily be imported/exported between H2O and Tensorflow since H2O uses Tensorflow's format for model definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def simple_model(w, h, channels, classes):\n",
    "    import json\n",
    "    import tensorflow as tf    \n",
    "    # always create a new graph inside ipython or\n",
    "    # the default one will be used and can lead to\n",
    "    # unexpected behavior\n",
    "    graph = tf.Graph() \n",
    "    with graph.as_default():\n",
    "        size = w * h * channels\n",
    "        x = tf.placeholder(tf.float32, [None, size])\n",
    "        W = tf.Variable(tf.zeros([size, classes]))\n",
    "        b = tf.Variable(tf.zeros([classes]))\n",
    "        y = tf.matmul(x, W) + b\n",
    "\n",
    "        # labels\n",
    "        y_ = tf.placeholder(tf.float32, [None, classes])\n",
    "     \n",
    "        # accuracy\n",
    "        correct_prediction = tf.equal(tf.argmax(y, 1),                                                                                                                                                                                                                                   \n",
    "                                       tf.argmax(y_, 1))                       \n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "        # train\n",
    "        cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, y_))\n",
    "        train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "        \n",
    "        tf.add_to_collection(\"train\", train_step)\n",
    "        # this is required by the h2o tensorflow backend\n",
    "        global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "        \n",
    "        init = tf.initialize_all_variables()\n",
    "        tf.add_to_collection(\"init\", init)\n",
    "        tf.add_to_collection(\"logits\", y)\n",
    "        saver = tf.train.Saver()\n",
    "        meta = json.dumps({\n",
    "                \"inputs\": {\"batch_image_input\": x.name, \"categorical_labels\": y_.name}, \n",
    "                \"outputs\": {\"categorical_logits\": y.name}, \n",
    "                \"metrics\": {\"accuracy\": accuracy.name, \"total_loss\": cross_entropy.name},\n",
    "                \"parameters\": {\"global_step\": global_step.name},\n",
    "        })\n",
    "        print(meta)\n",
    "        tf.add_to_collection(\"meta\", meta)\n",
    "        filename = \"/tmp/lenet_tensorflow.meta\"\n",
    "        tf.train.export_meta_graph(filename, saver_def=saver.as_saver_def())\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"metrics\": {\"total_loss\": \"Mean_1:0\", \"accuracy\": \"Mean:0\"}, \"inputs\": {\"categorical_labels\": \"Placeholder_1:0\", \"batch_image_input\": \"Placeholder:0\"}, \"parameters\": {\"global_step\": \"global_step:0\"}, \"outputs\": {\"categorical_logits\": \"add:0\"}}\n"
     ]
    }
   ],
   "source": [
    "filename = simple_model(28, 28, 3, classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepwater Model Build progress: |█████████████████████████████████████████| 100%\n",
      "Model Details\n",
      "=============\n",
      "H2ODeepWaterEstimator :  Deep Water\n",
      "Model Key:  deepwater_tf_custom\n",
      "\n",
      "\n",
      "ModelMetricsMultinomial: deepwater\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 6.60075876885e+12\n",
      "RMSE: 2569194.18668\n",
      "LogLoss: -14.4921790248\n",
      "Mean Per-Class Error: 0.0\n",
      "Confusion Matrix: vertical: actual; across: predicted\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>cat</b></td>\n",
       "<td><b>dog</b></td>\n",
       "<td><b>mouse</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>90.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 90</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>85.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 85</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>92.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 92</td></tr>\n",
       "<tr><td>90.0</td>\n",
       "<td>85.0</td>\n",
       "<td>92.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 267</td></tr></table></div>"
      ],
      "text/plain": [
       "cat    dog    mouse    Error    Rate\n",
       "-----  -----  -------  -------  -------\n",
       "90     0      0        0        0 / 90\n",
       "0      85     0        0        0 / 85\n",
       "0      0      92       0        0 / 92\n",
       "90     85     92       0        0 / 267"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-3 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    1\n",
       "2    1\n",
       "3    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>training_speed</b></td>\n",
       "<td><b>epochs</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>samples</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-11-30 09:20:03</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-11-30 09:20:05</td>\n",
       "<td> 2.017 sec</td>\n",
       "<td>534 obs/sec</td>\n",
       "<td>3.8352060</td>\n",
       "<td>1</td>\n",
       "<td>1024.0</td>\n",
       "<td>1327446.7778600</td>\n",
       "<td>nan</td>\n",
       "<td>0.5655431</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-11-30 09:20:10</td>\n",
       "<td> 7.083 sec</td>\n",
       "<td>9107 obs/sec</td>\n",
       "<td>237.7827715</td>\n",
       "<td>62</td>\n",
       "<td>63488.0</td>\n",
       "<td>2569194.1866800</td>\n",
       "<td>-14.4921790</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-11-30 09:20:15</td>\n",
       "<td>12.159 sec</td>\n",
       "<td>10548 obs/sec</td>\n",
       "<td>475.5655431</td>\n",
       "<td>124</td>\n",
       "<td>126976.0</td>\n",
       "<td>2569194.1866800</td>\n",
       "<td>-14.4921790</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-11-30 09:20:15</td>\n",
       "<td>12.745 sec</td>\n",
       "<td>10635 obs/sec</td>\n",
       "<td>502.4119850</td>\n",
       "<td>131</td>\n",
       "<td>134144.0</td>\n",
       "<td>2569194.1866800</td>\n",
       "<td>-14.4921790</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_classification_error\n",
       "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------------------------\n",
       "    2016-11-30 09:20:03  0.000 sec                     0         0             0          nan              nan                 nan\n",
       "    2016-11-30 09:20:05  2.017 sec   534 obs/sec       3.83521   1             1024       1.32745e+06      nan                 0.565543\n",
       "    2016-11-30 09:20:10  7.083 sec   9107 obs/sec      237.783   62            63488      2.56919e+06      -14.4922            0\n",
       "    2016-11-30 09:20:15  12.159 sec  10548 obs/sec     475.566   124           126976     2.56919e+06      -14.4922            0\n",
       "    2016-11-30 09:20:15  12.745 sec  10635 obs/sec     502.412   131           134144     2.56919e+06      -14.4922            0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = H2ODeepWaterEstimator(epochs                  = 500, \n",
    "                              network_definition_file = filename,  ## specify the model\n",
    "                              image_shape             = [28,28],  ## provide expected image size\n",
    "                              channels                = 3,\n",
    "                              backend                 = \"tensorflow\",\n",
    "                              model_id                = \"deepwater_tf_custom\")\n",
    "\n",
    "model.train(x = [0], # file path e.g. xxx/xxx/xxx.jpg\n",
    "            y = 1, # label cat/dog/mouse\n",
    "            training_frame = frame)\n",
    "\n",
    "model.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
