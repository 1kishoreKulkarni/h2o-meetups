{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to H2O with Python #\n",
    "\n",
    "This is an introductiory demo. Its purpose is to demonstrate the basic usage of Python client in H2O.\n",
    "\n",
    "## Outline ##\n",
    "\n",
    "1. Start H2O Cluster\n",
    "2. Import Data\n",
    "3. Train Model\n",
    "4. Predict\n",
    "5. Export MOJO and predict using MOJO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting H2O Cluster ##\n",
    "\n",
    "The default way how to start H2O Cluster is using `h2o.init()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please check the output of previous command. It contains various important information such as IP address of the H2O server, its version, age, etc.\n",
    "\n",
    "Now let us import data into the cluster. Data can be loaded form various sources (S3, HDFS, local file, etc.), but for purposes of this demo, we will use _local file_.\n",
    "\n",
    "You can get the dataset at `https://s3.amazonaws.com/benchm-ml--main/train-1m.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = h2o.import_file('/Users/michalraska/Development/h2o/datasets/train-1m.csv')\n",
    "data.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To distinguish between _regression_ and _classification_ problems H2O is checking the type of the response column. The `describe()` method is useful for checking the type of the columns as well as getting some additional information about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the previous output, we can see the response column is of type enum, which is correct. If we want to change the type of some column to enum, we will use `data['dep_delayed_15min'] = data['dep_delayed_15min'].asfactor()`. There are similar methods for other types, for example `asnumeric()`, `ascharacter()` or `as_date()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common practice, is to split the original data into two datasets: \n",
    "\n",
    "- training dataset\n",
    "- validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, validation = data.split_frame(ratios=[0.8], seed=1)\n",
    "print('Training dataset:')\n",
    "training.describe()\n",
    "print('Validation dataset:')\n",
    "validation.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a model in H2O, we need to import the `H2OGradientBoostingEstimator` in case of GBM. In case of other algorithms, for example the Distributed Random Forest, we would import `H2ORandomForestEstimator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we have to create an instance of `H2OGradientBoostingEstimator`. During instantiation various parameters can be specified. When no arguments are supplied, the defaults are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_model = H2OGradientBoostingEstimator(ntrees=120, model_id='gbm_airlines_python', seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the model, we have to specify the features - `x` (all columns except dep_delayed_15min) and response column - `y` (dep_delayed_15min). Besides these, we have to specify the training dataset - `training_frame`. The validation dataset - `validation_frame` is optional. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[:, 0:-1].col_names\n",
    "response = 'dep_delayed_15min'\n",
    "gbm_model.train(x=features, y='dep_delayed_15min', training_frame=training, validation_frame=validation)\n",
    "print(\"AUC Train: %f\" % gbm_model.auc(train=True))\n",
    "print(\"AUC Validation: %f\" % gbm_model.auc(valid=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Flow to monitor the training of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the trained model, we can use it to make some predictions. First we need to import the test dataset and then we can do the predictions, using the `predict()` method. The dataset can be downloaded from `https://s3.amazonaws.com/benchm-ml--main/test.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = h2o.import_file('/Users/michalraska/Development/h2o/datasets/test.csv')\n",
    "test.describe()\n",
    "prediction = gbm_model.predict(test)\n",
    "prediction.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are satisfied with the results, we export the model to MOJO - Model Object, Optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mojo_path = gbm_model.download_mojo(path=\"./\", get_genmodel_jar=True)\n",
    "print(\"Path to zip: %s\" % mojo_path)\n",
    "!ls -alh gbm_airlines_python.zip\n",
    "!ls -alh h2o-genmodel.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To score using MOJO we don't need H2O Cluster so shut it down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.cluster().shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the MOJO for predictions. For this, we will use the `mojo_predict_csv` from `h2o.utils.shared_utils` method. We will do predictions for the same CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import h2o.utils.shared_utils as h2o_utils\n",
    "prediction = h2o_utils.mojo_predict_csv(\n",
    "    input_csv_path='/Users/michalraska/Development/h2o/datasets/test.csv', \n",
    "    mojo_zip_path='./gbm_airlines_python.zip', \n",
    "    genmodel_jar_path='./h2o-genmodel.jar',\n",
    "    verbose=False\n",
    ")\n",
    "for i, p in enumerate(prediction[0:11]):\n",
    "    print(\"%s.\\tPredict: %s\\tN: %s\\tY: %s\" % ((i + 1), p['predict'], p['N'], p['Y']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
